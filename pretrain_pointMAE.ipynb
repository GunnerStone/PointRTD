{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Import Libraries ---\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from pointMAE import PointMAEModel  # Ensure PointMAE.py is in the same directory\n",
    "import os\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Define Hyperparameters ---\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CHECKPOINT_DIR = \"./checkpoints_pointmae\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "synset_to_class = {\n",
    "    \"02691156\": \"airplane\",\n",
    "    \"02747177\": \"ashcan\",\n",
    "    \"02773838\": \"bag\",\n",
    "    \"02801938\": \"bicycle\",\n",
    "    \"02808440\": \"boat\",\n",
    "    \"02818832\": \"bookcase\",\n",
    "    \"02828884\": \"bus\",\n",
    "    \"02843684\": \"cabinet\",\n",
    "    \"02871439\": \"car\",\n",
    "    \"02876657\": \"cellphone\",\n",
    "    \"02880940\": \"chair\",\n",
    "    \"02924116\": \"cone\",\n",
    "    \"02933112\": \"cup\",\n",
    "    \"02942699\": \"bench\",\n",
    "    \"02946921\": \"gun\",\n",
    "    \"02954340\": \"lamp\",\n",
    "    \"02958343\": \"laptop\",\n",
    "    \"02992529\": \"motorcycle\",\n",
    "    \"03001627\": \"piano\",\n",
    "    \"03046257\": \"rifle\",\n",
    "    \"03085013\": \"rocket\",\n",
    "    \"03207941\": \"skateboard\",\n",
    "    \"03211117\": \"sofa\",\n",
    "    \"03261776\": \"table\",\n",
    "    \"03325088\": \"tower\",\n",
    "    \"03337140\": \"train\",\n",
    "    \"03467517\": \"vehicle\",\n",
    "    \"03513137\": \"display\",\n",
    "    \"03593526\": \"washer\",\n",
    "    \"03624134\": \"clock\",\n",
    "    \"03636649\": \"dishwasher\",\n",
    "    \"03642806\": \"earphone\",\n",
    "    \"03691459\": \"firearm\",\n",
    "    \"03710193\": \"furniture\",\n",
    "    \"03759954\": \"fan\",\n",
    "    \"03761084\": \"hat\",\n",
    "    \"03790512\": \"helmet\",\n",
    "    \"03797390\": \"knife\",\n",
    "    \"03928116\": \"lamp\",\n",
    "    \"03938244\": \"loudspeaker\",\n",
    "    \"03948459\": \"mailbox\",\n",
    "    \"03991062\": \"microphone\",\n",
    "    \"04004475\": \"microwave\",\n",
    "    \"04074963\": \"mug\",\n",
    "    \"04099429\": \"pistol\",\n",
    "    \"04225987\": \"pot\",\n",
    "    \"04256520\": \"printer\",\n",
    "    \"04330267\": \"remote\",\n",
    "    \"04379243\": \"bathtub\",\n",
    "    \"04401088\": \"stove\",\n",
    "    \"04460130\": \"dishwasher\",\n",
    "    \"04468005\": \"telephone\",\n",
    "    \"04530566\": \"watercraft\",\n",
    "    \"04554684\": \"guitar\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Initialize Dataset and DataLoader ---\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from plyfile import PlyData\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from plyfile import PlyData\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class ShapeNetPointCloudDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', train_ratio=0.7, val_ratio=0.15, seed=42, augment=False, scale_range=(0.8, 1.2), translation_range=(-0.1, 0.1)):\n",
    "        \"\"\"\n",
    "        Initializes the ShapeNetPointCloudDataset with data split options based on class.\n",
    "\n",
    "        Args:\n",
    "            root_dir (str): Path to the ShapeNetCore directory.\n",
    "            split (str): Which data split to use ('train', 'val', or 'test').\n",
    "            train_ratio (float): Proportion of data for training.\n",
    "            val_ratio (float): Proportion of data for validation.\n",
    "            seed (int): Random seed for reproducibility.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.data = []  # Stores tuples of (file_path, class_label)\n",
    "        self.augment = augment\n",
    "        self.scale_range = scale_range\n",
    "        self.translation_range = translation_range\n",
    "\n",
    "        # Collect file paths organized by class\n",
    "        class_files = self.get_class_files()\n",
    "\n",
    "        # Generate class_name_to_index mapping\n",
    "        self.class_name_to_index = {class_name: idx for idx, class_name in enumerate(class_files.keys())}\n",
    "        \n",
    "        # Split each class's files into train, val, and test sets\n",
    "        self.create_splits(class_files, train_ratio, val_ratio, seed)\n",
    "\n",
    "    def get_class_files(self):\n",
    "        \"\"\"\n",
    "        Collects .ply file paths for each class in the ShapeNet directory.\n",
    "        Returns:\n",
    "            dict: A dictionary where keys are class labels, and values are lists of file paths.\n",
    "        \"\"\"\n",
    "        class_files = {synset_to_class[synset]: [] for synset in synset_to_class}\n",
    "        for synset_id, class_name in synset_to_class.items():\n",
    "            synset_dir = os.path.join(self.root_dir, synset_id)\n",
    "            for dirpath, _, files in os.walk(synset_dir):\n",
    "                for file_name in files:\n",
    "                    if file_name.endswith('.ply'):\n",
    "                        class_files[class_name].append(os.path.join(dirpath, file_name))\n",
    "        return class_files\n",
    "\n",
    "    def create_splits(self, class_files, train_ratio, val_ratio, seed):\n",
    "        \"\"\"\n",
    "        Splits the dataset into train, val, and test sets based on specified ratios.\n",
    "        \n",
    "        Args:\n",
    "            class_files (dict): Dictionary of class labels to lists of file paths.\n",
    "            train_ratio (float): Proportion of data for training.\n",
    "            val_ratio (float): Proportion of data for validation.\n",
    "            seed (int): Random seed for reproducibility.\n",
    "        \"\"\"\n",
    "        random.seed(seed)\n",
    "        for class_name, files in class_files.items():\n",
    "            random.shuffle(files)\n",
    "            total_files = len(files)\n",
    "            train_len = int(total_files * train_ratio)\n",
    "            val_len = int(total_files * val_ratio)\n",
    "\n",
    "            if self.split == 'train':\n",
    "                split_files = files[:train_len]\n",
    "            elif self.split == 'val':\n",
    "                split_files = files[train_len:train_len + val_len]\n",
    "            elif self.split == 'test':\n",
    "                split_files = files[train_len + val_len:]\n",
    "            else:\n",
    "                raise ValueError(\"Invalid split; choose from 'train', 'val', or 'test'.\")\n",
    "\n",
    "            self.data.extend([(file_path, class_name) for file_path in split_files])\n",
    "\n",
    "    def apply_augmentations(self, points):\n",
    "        \"\"\"\n",
    "        Applies random scaling and translation to the point cloud.\n",
    "        \n",
    "        Args:\n",
    "            points (np.ndarray): Point cloud data, shape (num_points, 3).\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Augmented point cloud.\n",
    "        \"\"\"\n",
    "        # Random scaling\n",
    "        scale_factor = np.random.uniform(*self.scale_range)\n",
    "        points *= scale_factor\n",
    "\n",
    "        # Random translation\n",
    "        translation = np.random.uniform(*self.translation_range, size=(1, 3))\n",
    "        points += translation\n",
    "\n",
    "        return points\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Reads a .ply file, subsamples the point cloud, and returns the point cloud and its class label as a tensor.\n",
    "        \n",
    "        Args:\n",
    "            idx (int): Index of the item in the dataset.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: A tuple containing:\n",
    "                - points (torch.Tensor): Subsampled point cloud data of shape (num_points, 3).\n",
    "                - class_index (int): Class index for the point cloud.\n",
    "        \"\"\"\n",
    "        num_points = 1024  # Desired number of points after subsampling\n",
    "        file_path, class_label = self.data[idx]\n",
    "        ply_data = PlyData.read(file_path)\n",
    "        points = np.vstack([\n",
    "            np.array(ply_data['vertex'][axis]) for axis in ['x', 'y', 'z']\n",
    "        ]).T  # Shape (N, 3)\n",
    "\n",
    "        # Subsample points if necessary\n",
    "        if points.shape[0] > num_points:\n",
    "            indices = np.random.choice(points.shape[0], num_points, replace=False)\n",
    "            points = points[indices]\n",
    "        elif points.shape[0] < num_points:\n",
    "            # Pad with zeros if there are fewer than num_points\n",
    "            padding = np.zeros((num_points - points.shape[0], 3))\n",
    "            points = np.vstack([points, padding])\n",
    "\n",
    "        # Apply augmentations if enabled and split is 'train'\n",
    "        if self.augment and self.split == 'train':\n",
    "            points = self.apply_augmentations(points)\n",
    "\n",
    "        # Convert class label to class index\n",
    "        class_index = self.class_name_to_index[class_label]\n",
    "        \n",
    "        return torch.tensor(points, dtype=torch.float32), class_index\n",
    "\n",
    "\n",
    "\n",
    "# Usage\n",
    "\n",
    "# Create datasets for each split\n",
    "root_dir = './ShapeNetCore.v2'\n",
    "train_dataset = ShapeNetPointCloudDataset(root_dir, split='train', augment=True)\n",
    "val_dataset = ShapeNetPointCloudDataset(root_dir, split='val', augment=False)\n",
    "test_dataset = ShapeNetPointCloudDataset(root_dir, split='test', augment=False)\n",
    "\n",
    "# Create DataLoaders for each split\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Initialize PointMAE Model, Optimizer, and Scheduler ---\n",
    "token_dim = 256\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "num_patches = 64\n",
    "num_pts_per_patch = 32\n",
    "num_channels = 3\n",
    "mask_ratio = 0.65\n",
    "\n",
    "# Initialize PointMAE Model\n",
    "model = PointMAEModel(\n",
    "    input_dim=num_channels,\n",
    "    token_dim=token_dim,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    mask_ratio=mask_ratio,\n",
    "    num_patches=num_patches,\n",
    "    num_pts_per_patch=num_pts_per_patch,\n",
    ").to(DEVICE)\n",
    "\n",
    "# Initialize optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.05)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=300, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Batch [0/1096], Reconstruction Loss: 1.8902\n",
      "Epoch [1/100], Batch [10/1096], Reconstruction Loss: 2.0603\n",
      "Epoch [1/100], Batch [20/1096], Reconstruction Loss: 0.5427\n",
      "Epoch [1/100], Batch [30/1096], Reconstruction Loss: 0.2794\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      4\u001b[0m total_reconstruction_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m      7\u001b[0m     pointclouds, _ \u001b[38;5;241m=\u001b[39m data  \u001b[38;5;66;03m# Only pointcloud data needed for PointMAE pretraining\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     pointclouds \u001b[38;5;241m=\u001b[39m pointclouds\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[5], line 123\u001b[0m, in \u001b[0;36mShapeNetPointCloudDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    121\u001b[0m num_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m  \u001b[38;5;66;03m# Desired number of points after subsampling\u001b[39;00m\n\u001b[0;32m    122\u001b[0m file_path, class_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n\u001b[1;32m--> 123\u001b[0m ply_data \u001b[38;5;241m=\u001b[39m PlyData\u001b[38;5;241m.\u001b[39mread(file_path)\n\u001b[0;32m    124\u001b[0m points \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([\n\u001b[0;32m    125\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(ply_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertex\u001b[39m\u001b[38;5;124m'\u001b[39m][axis]) \u001b[38;5;28;01mfor\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    126\u001b[0m ])\u001b[38;5;241m.\u001b[39mT  \u001b[38;5;66;03m# Shape (N, 3)\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# Subsample points if necessary\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch\\Lib\\site-packages\\plyfile.py:172\u001b[0m, in \u001b[0;36mPlyData.read\u001b[1;34m(stream, mmap, known_list_len)\u001b[0m\n\u001b[0;32m    170\u001b[0m             data_stream \u001b[38;5;241m=\u001b[39m stream\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m elt \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m--> 172\u001b[0m         elt\u001b[38;5;241m.\u001b[39m_read(data_stream, data\u001b[38;5;241m.\u001b[39mtext, data\u001b[38;5;241m.\u001b[39mbyte_order, mmap,\n\u001b[0;32m    173\u001b[0m                   known_list_len\u001b[38;5;241m=\u001b[39mknown_list_len\u001b[38;5;241m.\u001b[39mget(elt\u001b[38;5;241m.\u001b[39mname, {}))\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m must_close:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch\\Lib\\site-packages\\plyfile.py:513\u001b[0m, in \u001b[0;36mPlyElement._read\u001b[1;34m(self, stream, text, byte_order, mmap, known_list_len)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;124;03mRead the actual data from a PLY file.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03mknown_list_len : dict\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text:\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_txt(stream)\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    515\u001b[0m     list_prop_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(p\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties\n\u001b[0;32m    516\u001b[0m                           \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(p, PlyListProperty))\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch\\Lib\\site-packages\\plyfile.py:613\u001b[0m, in \u001b[0;36mPlyElement._read_txt\u001b[1;34m(self, stream)\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m _np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype())\n\u001b[0;32m    612\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 613\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m _islice(\u001b[38;5;28miter\u001b[39m(stream\u001b[38;5;241m.\u001b[39mreadline, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount):\n\u001b[0;32m    614\u001b[0m     fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit())\n\u001b[0;32m    615\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prop \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch\\Lib\\encodings\\ascii.py:25\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIncrementalDecoder\u001b[39;00m(codecs\u001b[38;5;241m.\u001b[39mIncrementalDecoder):\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mascii_decode(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- 5. Training Loop ---\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_reconstruction_loss = 0.0\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        pointclouds, _ = data  # Only pointcloud data needed for PointMAE pretraining\n",
    "        pointclouds = pointclouds.to(DEVICE)\n",
    "        \n",
    "        # Forward pass through PointMAE model\n",
    "        reconstructed_patches, original_patches = model(pointclouds)\n",
    "\n",
    "        # Calculate Chamfer Distance as reconstruction loss\n",
    "        reconstruction_loss = model.get_loss(reconstructed_patches, original_patches)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        reconstruction_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate losses for logging\n",
    "        total_reconstruction_loss += reconstruction_loss.item()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1}/{EPOCHS}], Batch [{batch_idx}/{len(train_loader)}], \"\n",
    "                f\"Reconstruction Loss: {reconstruction_loss.item():.4f}\"\n",
    "            )\n",
    "\n",
    "    # Step the scheduler after each epoch\n",
    "    scheduler.step()\n",
    "\n",
    "    # Log epoch-wise loss\n",
    "    avg_reconstruction_loss = total_reconstruction_loss / len(train_loader)\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{EPOCHS}] - Avg Reconstruction Loss: {avg_reconstruction_loss:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Save checkpoint every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"pointmae_epoch_{epoch+1}.pth\")\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
